{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aims and Objectives\n",
    "This study will aim to investigate the effect of funding on local school results. Two datasets will be used to determine this; one details pupils’ attainment at the end of KS2, and one contains details related to school funding.\n",
    "\n",
    "This study will consider two questions; \n",
    "- Do local authorities allocate funding in a similar fashion to how the central government fund academies? \n",
    "- Does more funding allocation in a local authority correlate with increased average scores for the local community schools?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the required libraries (more added as running through notebook)\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# First import and review of funding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# By default when importing an excel sheet, only the first sheet is imported if not sheet is called.\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at the list of tables, a few tables that may be useful are:\n",
    "- Table 6\n",
    "- Table 7\n",
    "- Table 8\n",
    "- Table 9\n",
    "- Table 10\n",
    "- Table 11\n",
    "- Table 12\n",
    "\n",
    "I will import each of these tables in below to see what data they provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 6\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 6').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 7\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 7').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 8 -\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 8').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 9 -\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 9').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 10 -\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 10').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 11\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 11').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing table 12\n",
    "pd.read_excel('data/SR63_2016_Tables.xlsx', sheetname='Table 12').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at the above tables, the one that appears to be most relevant is table 12; I will clean up the table via OpenRefine and import in the cleaned data.\n",
    "\n",
    "I also analysed the SFR27_2016_Main_Tables.xlsx dataset and found that the most beneficial table was the RAW Data SATs; I will also clean this table via OpenRefine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the KS2 data\n",
    "In order to import the KS2, a few steps will be required:\n",
    "<br>1) Import the LEA data\n",
    "<br>2) Import and clean up the KS2 data \n",
    "<br>3) Merge the LEA and KS2 data\n",
    "\n",
    "These steps were provided by the OU in TMA02, so those steps can be reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the LEA data\n",
    "The LEA data provides all the Local Authority (LA) and region codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leas_df = pd.read_csv('data/2015-2016/la_and_region_codes_meta.csv')\n",
    "leas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import and clean up the KS2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2cols = pd.read_csv('data/2015-2016/ks2_meta.csv')\n",
    "ks2cols['Field Name'] = ks2cols['Field Name'].apply(lambda r: r.strip(),)\n",
    "ks2cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some columns contain int values, but pandas will treat a numeric column with na values as float64, so the int columns will need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "int_cols = [c for c in ks2cols['Field Name'] \n",
    "            if c.startswith('T')\n",
    "            if c not in ['TOWN', 'TELNUM', 'TKS1AVERAGE']]\n",
    "int_cols += ['RECTYPE', 'ALPHAIND', 'LEA', 'ESTAB', 'URN', 'URN_AC', 'ICLOSE']\n",
    "int_cols += ['READ_AVERAGE', 'GPS_AVERAGE', 'MAT_AVERAGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Any columns that contain percentages will be converted to floating point numbers during import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def p2f(x):\n",
    "    if x.strip('%').isnumeric():\n",
    "        return float(x.strip('%'))/100\n",
    "    elif x in ['SUPP', 'NEW', 'LOWCOV', 'NA', '']:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "percent_cols = [f for f in ks2cols['Field Name'] if f.startswith('P')]\n",
    "percent_cols += ['WRITCOV', 'MATCOV', 'READCOV'] \n",
    "percent_cols += ['PTMAT_HIGH', 'PTREAD_HIGH', 'PSENELSAPK', 'PSENELK', 'PTGPS_HIGH']\n",
    "percent_converters = {c: p2f for c in percent_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Inital import of the KS2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_df = pd.read_csv('data/2015-2016/england_ks2final.csv', \n",
    "                   na_values=['SUPP', 'NEW', 'LOWCOV', 'NA', ''],\n",
    "                   converters=percent_converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(ks2_df['RECTYPE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5 record types exist - Record type (1=mainstream school; 2=special school; 3=Local Authority; 4=National (all schools); 5=National (maintained schools))<br>\n",
    "The only ones required are 1 and 2, so the other record types can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_df = ks2_df[(ks2_df['RECTYPE'] == 1) | (ks2_df['RECTYPE'] == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All values should be converted to numbers where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_df = ks2_df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the LEA and KS2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_df = pd.merge(ks2_df, leas_df, on=['LEA'])\n",
    "ks2_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# KS2 data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first step I will take to analyse the data is to identify the different school types, and the counts of each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checked via Excel - rows 3 to 26 are relevant\n",
    "school_types_df = pd.read_excel('data/2015-2016/abbreviations.xlsx')[3:26]\n",
    "school_types_df.drop('Unnamed: 2', axis=1, inplace=True)\n",
    "school_types_df.rename(columns={ school_types_df.columns[0]: \"NFTYPE\", school_types_df.columns[1]: 'Description'} , inplace=True)\n",
    "school_types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "school_types_df.to_csv('data/school_types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_df['NFTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In order to identify which school types are funded by Local Authorities and which are funded by Central Government, I searched various online resources:<br>\n",
    "<br>http://www.bbc.co.uk/schools/parents/types_of_schools/\n",
    "<br>https://www.gov.uk/types-of-school/city-technology-colleges\n",
    "<br>https://www.newschoolsnetwork.org/set-up-a-free-school/frequently-asked-questions/how-are-free-schools-funded\n",
    "<br>https://en.wikipedia.org/wiki/University_technical_college\n",
    "\n",
    "Each school type has been placed into a FundingBody category. These categories may change as I perform further investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "st_fb_df = pd.read_csv('data/school_types_with_funding_bodies.csv')\n",
    "st_fb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next I will identify the school types that appear in the KS2 dataset, as that should narrow down the number of school types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_st_df = ks2_df['NFTYPE'].unique()\n",
    "\n",
    "ks2_st_list = ks2_st_df.tolist()\n",
    "\n",
    "ks2_st_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ks2_st_fb_df = st_fb_df.loc[st_fb_df['NFTYPE'].isin(ks2_st_list)]\n",
    "\n",
    "ks2_st_fb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"st_fb_df row count: \" + str(len(st_fb_df)))\n",
    "print(\"ks2_st_fb_df row count: \" + str(len(ks2_st_fb_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KS2 final review and import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have identified the columns that I would require from the ks2_df dataset in order for the questions to be answered:\n",
    "- RECTYPE - this is the type of record; only values 1 or 2 are relevant as they refer to mainstream and special schools (KS2 dataset)\n",
    "- AILPHAIND - Alphabetic Index (KS2 dataset)\n",
    "- LEA - Local Authority number (KS2 dataset)\n",
    "- ESTAB - Establishment number (KS2 dataset)\n",
    "- URN - School UID (KS2 dataset)\n",
    "- SCHNAME - School name (kS2 dataset)\n",
    "- NFTYPE - School type (KS2 dataset)\n",
    "- READ_AVERAGE - Reading average (KS2 dataset)\n",
    "- GPS_AVERAGE - Grammar, punctuation and spelling average\n",
    "- MAT_AVERAGE - Maths average\n",
    "- LA Name - Local Authority Name (LA and Region codes meta dataset)\n",
    "- REGION - Region number (LA and Region codes meta dataset)\n",
    "- REGION NAME - Region name (LA and Region codes meta dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_df = ks2_df[['RECTYPE', 'ALPHAIND', 'LEA', 'ESTAB', 'URN', 'SCHNAME', 'NFTYPE', 'READ_AVERAGE', 'GPS_AVERAGE', 'MAT_AVERAGE', 'LA Name', 'REGION', 'REGION NAME']]\n",
    "\n",
    "#Drop any rows that contain NA values\n",
    "ks2_df.dropna(inplace=True)\n",
    "\n",
    "int_cols = ['RECTYPE', 'ALPHAIND', 'LEA', 'ESTAB', 'URN', 'READ_AVERAGE', 'GPS_AVERAGE', 'MAT_AVERAGE', 'REGION']\n",
    "\n",
    "for col in int_cols:\n",
    "    ks2_df[col] = ks2_df[col].astype(int)\n",
    "\n",
    "\n",
    "ks2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second import and review of funding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleaned the funding datasets via OpenRefine so it could be imported easier into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr63_df = pd.read_csv('data/SR63_T12_cleaned.csv')\n",
    "\n",
    "len(sr63_df)\n",
    "\n",
    "sr63_df.head()\n",
    "\n",
    "for k in sr63_df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr27_df = pd.read_csv('data/SFR27_RDS_cleaned.csv')\n",
    "\n",
    "len(sfr27_df)\n",
    "\n",
    "sfr27_df.head()\n",
    "\n",
    "for k in sfr27_df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KS2 dataset and two funding datasets can be combined through a concatenation of the LA number and Estab number; \n",
    "I will create a common field between the three datasets called _LAESTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create _LAESTAB column on ks2_df to allow join to funding data\n",
    "ks2_df['_LAESTAB'] = ks2_df['LEA'].map(str) + ks2_df['ESTAB'].map(str)\n",
    "\n",
    "# Convert _LAESTAB to int\n",
    "ks2_df['_LAESTAB'] = ks2_df['_LAESTAB'].astype(int)\n",
    "\n",
    "ks2_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LA-ESTAB column on sfr27_df\n",
    "sfr27_df['_LAESTAB'] = sfr27_df['LA'].map(str) + sfr27_df['Estab'].map(str)\n",
    "\n",
    "# Convert _LAESTAB to int\n",
    "sfr27_df['_LAESTAB'] = sfr27_df['_LAESTAB'].astype(int)\n",
    "\n",
    "sfr27_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename LA/ESTAB number column on sr63_df to _LAESTAB\n",
    "sr63_df.rename(columns={'LA/ESTAB number' : '_LAESTAB', 'Total revenue balance (1)': \n",
    "                                    'Total revenue balance'}, inplace=True)\n",
    "\n",
    "sr63_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two balance fields from the funding datasets appear to have different scales for the amount; to match them, I will multiply the <strong>Total Grant funding £000</strong> and <strong>Total Income £000</strong> sfr27_df dataframe by 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr27_df['_TotalGrantFunding'] = sfr27_df['Total Grant Funding  £000'] * 1000\n",
    "sfr27_df['_TotalIncome'] = sfr27_df['Total Income  £000'] * 1000\n",
    "sfr27_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    ks2.*,\n",
    "    COALESCE(sr63.\"Total revenue balance\", sfr27.\"_TotalGrantFunding\") AS _BALANCE\n",
    "FROM\n",
    "    ks2_df ks2\n",
    "    LEFT JOIN sr63_df  sr63  ON ks2.\"_LAESTAB\" =  sr63.\"_LAESTAB\"\n",
    "    LEFT JOIN sfr27_df sfr27 ON ks2.\"_LAESTAB\" = sfr27.\"_LAESTAB\"\n",
    "'''\n",
    "\n",
    "ks2_funding_df = pysqldf(query)\n",
    "\n",
    "# Remove rows with NaN value for _BALANCE\n",
    "ks2_funding_df.dropna(inplace=True)\n",
    "ks2_funding_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing ks2_funding_df in new variable - ks2_funding2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    RECTYPE,\n",
    "    ALPHAIND,\n",
    "    LEA,\n",
    "    ESTAB,\n",
    "    URN,\n",
    "    SCHNAME,\n",
    "    NFTYPE,\n",
    "    READ_AVERAGE,\n",
    "    GPS_AVERAGE,\n",
    "    MAT_AVERAGE,\n",
    "    \"LA Name\",\n",
    "    REGION,\n",
    "    \"REGION NAME\",\n",
    "    _LAESTAB,\n",
    "    CASE\n",
    "    WHEN _BALANCE LIKE '%,%' THEN REPLACE(_BALANCE, ',', '')\n",
    "    ELSE _BALANCE\n",
    "    END AS _BALANCE\n",
    "FROM\n",
    "    ks2_funding_df\n",
    "'''\n",
    "\n",
    "ks2_funding2_df = pysqldf(query)\n",
    "ks2_funding2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_df['_BALANCE'] = ks2_funding2_df['_BALANCE'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "ks2_funding2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT\n",
    "NFTYPE\n",
    "FROM\n",
    "ks2_funding2_df'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ks2_funding2_df\n",
    "WHERE\n",
    "    _BALANCE IS NOT NULL AND _BALANCE > 0\n",
    "'''\n",
    "\n",
    "ks2_funding2_df = pysqldf(query)\n",
    "ks2_funding2_df.sort_values(by=['_BALANCE'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT\n",
    "NFTYPE\n",
    "FROM\n",
    "ks2_funding2_df\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    NFTYPE,\n",
    "    COUNT(*) AS _SCHOOLCOUNT,\n",
    "    AVG(_BALANCE) AS _AVGBALANCE,\n",
    "    MAX(_BALANCE) AS _MAXBALANCE,\n",
    "    MIN(_BALANCE) AS _MINBALANCE\n",
    "FROM\n",
    "    ks2_funding2_df\n",
    "GROUP by\n",
    "    NFTYPE'''\n",
    "\n",
    "ks2_funding_avg_df = pysqldf(query)\n",
    "ks2_funding_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_avg_df = pd.merge(ks2_funding_avg_df, ks2_st_fb_df, how=\"inner\", on=\"NFTYPE\")\n",
    "\n",
    "ks2_funding2_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_avg_df['_AVGBALANCE'] = ks2_funding2_avg_df['_AVGBALANCE'] / 1000\n",
    "\n",
    "ks2_funding2_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_avg_df.rename(columns={\"_AVGBALANCE\" : \"AVGBALANCE (000s)\"}, inplace=True)\n",
    "\n",
    "ks2_funding2_avg_df['AVGBALANCE (000s)'] = ks2_funding2_avg_df['AVGBALANCE (000s)'].astype(int)\n",
    "\n",
    "ks2_funding2_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks2_funding2_avg_df['AVGBALANCE (000s)'] = ks2_funding2_avg_df['AVGBALANCE (000s)'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_avg_df.rename(columns={\"AVGBALANCE (000s)\" : \"_AVGBALANCE\"}, inplace=True)\n",
    "ks2_funding2_avg_df.sort_values(by=['_AVGBALANCE'],ascending=False, inplace=True)\n",
    "ks2_funding2_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_avg_bar = ks2_funding2_avg_df.plot.bar(\n",
    "    x='Description',\n",
    "    y='_AVGBALANCE',\n",
    "    color=[np.where(ks2_funding2_avg_df['FundingBody']=='Central Government', 'red', 'blue')],\n",
    "    title='Average Balance Per School Type',\n",
    "    legend=False,\n",
    "    figsize=(10, 7)\n",
    "    )\n",
    "\n",
    "for p in ks2_funding2_avg_bar.patches:\n",
    "    ks2_funding2_avg_bar.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding2_df = pd.merge(ks2_funding2_df, ks2_st_fb_df, how=\"inner\", on=\"NFTYPE\")\n",
    "ks2_funding2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    SCHNAME,\n",
    "    Description,\n",
    "    FundingBody,\n",
    "    _BALANCE\n",
    "FROM\n",
    "    ks2_funding2_df\n",
    "ORDER BY\n",
    "    _BALANCE DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    SCHNAME,\n",
    "    Description,\n",
    "    FundingBody,\n",
    "    _BALANCE\n",
    "FROM\n",
    "    ks2_funding2_df\n",
    "ORDER BY\n",
    "    _BALANCE ASC\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Do local authorities allocate funding in a similar fashion to how the central government fund academies?</h1>\n",
    "Looking at both the bar chart and the tables showing the top and bottom 30 balances from the ks2_funding2_df DataFrame, it appears that the Central Government allocate much higher funding to Academies than Local Authorities allocate to Community, Foundation and Voluntary schools. One reason for the higher funding may be due to Academies not being required to follow the national curriculum, so may provide other subjects that require higher funding (https://fullfact.org/education/academies-and-maintained-schools-what-do-we-know/). Another reason could be the size of Academies are generally larger than other school types, so higher running costs may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KS2 and funding comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step  is to find if the funding allocated affects the results; I will attempt to use data mining to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2_funding3_df = ks2_funding2_df.copy()\n",
    "\n",
    "ks2_funding3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "SELECT\n",
    "    READ_AVERAGE,\n",
    "    _BALANCE\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "ORDER BY\n",
    "    1\n",
    "'''\n",
    "\n",
    "read_avg_bal_df = pysqldf(query)\n",
    "\n",
    "read_avg_bal_df.plot.scatter(\n",
    "    x='READ_AVERAGE', \n",
    "    y='_BALANCE',\n",
    "    title='READ AVERAGE PER BALANCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the basic graph containing the read average per balance, it appears there is a almost perfect bell curve with the data; I will investigate this further by clustering the data to see if any patterns appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    READ_AVERAGE,\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "GROUP BY\n",
    "    READ_AVERAGE\n",
    "ORDER BY\n",
    "    1\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://code.activestate.com/recipes/425397-split-a-list-into-roughly-equal-sized-pieces/\n",
    "def split_seq(seq, size):\n",
    "        newseq = []\n",
    "        splitsize = 1.0/size*len(seq)\n",
    "        for i in range(size):\n",
    "                newseq.append(seq[int(round(i*splitsize)):int(round((i+1)*splitsize))])\n",
    "        return newseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT\n",
    "    READ_AVERAGE\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "ORDER BY\n",
    "    1\n",
    "'''\n",
    "\n",
    "ra_df = pysqldf(query)\n",
    "\n",
    "split_seq(ra_df.values.tolist(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN READ_AVERAGE BETWEEN 89 AND 98 THEN \"LOW\"\n",
    "        WHEN READ_AVERAGE BETWEEN 99 AND 106 THEN \"MEDIUM\"\n",
    "        WHEN READ_AVERAGE > 106 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS CAT,\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "GROUP BY\n",
    "    \"CAT\"\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above categories are in the clusters that should be assigned (in theory) to the data. I'm going to do the same for GPS_AVERAGE and MAT_AVERAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT\n",
    "    GPS_AVERAGE\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "ORDER BY\n",
    "    1\n",
    "'''\n",
    "\n",
    "ra_df = pysqldf(query)\n",
    "\n",
    "split_seq(ra_df.values.tolist(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN GPS_AVERAGE BETWEEN 91 AND 99 THEN \"LOW\"\n",
    "        WHEN GPS_AVERAGE BETWEEN 100 AND 107 THEN \"MEDIUM\"\n",
    "        WHEN GPS_AVERAGE > 107 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS CAT,\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "GROUP BY\n",
    "    \"CAT\"\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT\n",
    "    MAT_AVERAGE\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "ORDER BY\n",
    "    1\n",
    "'''\n",
    "\n",
    "ra_df = pysqldf(query)\n",
    "\n",
    "split_seq(ra_df.values.tolist(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN MAT_AVERAGE BETWEEN 90 AND 98 THEN \"LOW\"\n",
    "        WHEN MAT_AVERAGE BETWEEN 99 AND 106 THEN \"MEDIUM\"\n",
    "        WHEN MAT_AVERAGE > 106 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS CAT,\n",
    "    COUNT(*)\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "GROUP BY\n",
    "    \"CAT\"\n",
    "'''\n",
    "\n",
    "pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    RECTYPE,\n",
    "    ALPHAIND,\n",
    "    LEA,\n",
    "    ESTAB,\n",
    "    URN,\n",
    "    SCHNAME,\n",
    "    NFTYPE,\n",
    "    READ_AVERAGE,\n",
    "    GPS_AVERAGE,\n",
    "    MAT_AVERAGE,\n",
    "    \"LA Name\",\n",
    "    REGION,\n",
    "    \"REGION NAME\",\n",
    "    _LAESTAB,\n",
    "    CASE\n",
    "        WHEN _BALANCE LIKE '%,%' THEN REPLACE(_BALANCE, ',', '')\n",
    "        ELSE _BALANCE\n",
    "    END AS _BALANCE,\n",
    "    CASE\n",
    "        WHEN READ_AVERAGE BETWEEN 89 AND 98 THEN \"LOW\"\n",
    "        WHEN READ_AVERAGE BETWEEN 99 AND 106 THEN \"MEDIUM\"\n",
    "        WHEN READ_AVERAGE > 106 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS READ_CAT,\n",
    "    CASE\n",
    "        WHEN GPS_AVERAGE BETWEEN 91 AND 99 THEN \"LOW\"\n",
    "        WHEN GPS_AVERAGE BETWEEN 100 AND 107 THEN \"MEDIUM\"\n",
    "        WHEN GPS_AVERAGE > 107 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS GPS_CAT,\n",
    "    CASE\n",
    "        WHEN MAT_AVERAGE BETWEEN 90 AND 98 THEN \"LOW\"\n",
    "        WHEN MAT_AVERAGE BETWEEN 99 AND 106 THEN \"MEDIUM\"\n",
    "        WHEN MAT_AVERAGE > 106 THEN \"HIGH\"\n",
    "        ELSE NULL\n",
    "    END AS MAT_CAT\n",
    "FROM\n",
    "    ks2_funding3_df\n",
    "'''\n",
    "\n",
    "ks2_funding3_df = pysqldf(query)\n",
    "\n",
    "ks2_funding3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have assigned the manual clusters, I will use K-Means to see if the categories match up with the similar numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans3 = cluster.KMeans(n_clusters=3)\n",
    "\n",
    "clusteringData_df = ks2_funding3_df[['READ_AVERAGE', '_BALANCE']]\n",
    "\n",
    "assignedClusters_clust = kmeans3.fit(clusteringData_df)\n",
    "\n",
    "Counter(assignedClusters_clust.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points which in the cluster labelled '0'\n",
    "plt.scatter(ks2_funding3_df['READ_AVERAGE'][assignedClusters_clust.labels_==0],\n",
    "            ks2_funding3_df['_BALANCE'][assignedClusters_clust.labels_==0],\n",
    "            color='red', marker='o', label='cluster 0')\n",
    "\n",
    "# Plot the data points which in the cluster labelled '1'\n",
    "plt.scatter(ks2_funding3_df['READ_AVERAGE'][assignedClusters_clust.labels_==1],\n",
    "            ks2_funding3_df['_BALANCE'][assignedClusters_clust.labels_==1],\n",
    "            color='blue', marker='o', label='cluster 1')\n",
    "\n",
    "# Plot the data points which in the cluster labelled '2'\n",
    "plt.scatter(ks2_funding3_df['READ_AVERAGE'][assignedClusters_clust.labels_==2],\n",
    "            ks2_funding3_df['_BALANCE'][assignedClusters_clust.labels_==2],\n",
    "            color='green', marker='o', label='cluster 2')\n",
    "\n",
    "for (cx, cy) in assignedClusters_clust.cluster_centers_:\n",
    "    plt.plot(cx, cy, color='black', marker='x', mew=2)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('READ_AVERAGE')\n",
    "plt.ylabel('BALANCE')\n",
    "\n",
    "plt.title('3-means Clustering with centroids (full dataset)')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteringDataSample_df = clusteringData_df.sample(n=int(len(clusteringData_df) / 2))\n",
    "\n",
    "kmeans3 = KMeans(n_clusters=3)\n",
    "assignedClusters = kmeans3.fit(clusteringDataSample_df)\n",
    "\n",
    "assignedClusters.labels_\n",
    "\n",
    "\n",
    "silhouetteData_df = pd.DataFrame({'silhouette':silhouette_samples(clusteringDataSample_df,\n",
    "                                                                  assignedClusters.labels_),\n",
    "                                  'cluster':assignedClusters.labels_})\n",
    "\n",
    "silhouetteData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouetteData_df.sort_values(['cluster', 'silhouette'], inplace=True)\n",
    "silhouetteData_df.index = range(len(silhouetteData_df))\n",
    "\n",
    "colourMap = {0:'red',\n",
    "             1:'blue',\n",
    "             2:'lightGreen'}\n",
    "\n",
    "for cluster in set(silhouetteData_df['cluster']):\n",
    "    plt.bar(silhouetteData_df[silhouetteData_df['cluster']==cluster].index,\n",
    "            silhouetteData_df[silhouetteData_df['cluster']==cluster]['silhouette'],\n",
    "            color=colourMap[cluster],\n",
    "            label='Cluster {}'.format(cluster), width=1)\n",
    "\n",
    "plt.title('Silhouette plot of KS2 READ AVERAGE data, clustered with $k$-means, $k$=3 (50% Sample)')\n",
    "\n",
    "plt.xlabel('Number of data point')\n",
    "plt.ylabel('Silhouette coefficient')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim((-0.2, 1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points which in the cluster labelled '0'\n",
    "plt.scatter(clusteringDataSample_df['READ_AVERAGE'][assignedClusters.labels_==0],\n",
    "            clusteringDataSample_df['_BALANCE'][assignedClusters.labels_==0],\n",
    "            color='red', marker='o', label='cluster 0')\n",
    "\n",
    "# Plot the data points which in the cluster labelled '1'\n",
    "plt.scatter(clusteringDataSample_df['READ_AVERAGE'][assignedClusters.labels_==1],\n",
    "            clusteringDataSample_df['_BALANCE'][assignedClusters.labels_==1],\n",
    "            color='blue', marker='o', label='cluster 1')\n",
    "\n",
    "# Plot the data points which in the cluster labelled '2'\n",
    "plt.scatter(clusteringDataSample_df['READ_AVERAGE'][assignedClusters.labels_==2],\n",
    "            clusteringDataSample_df['_BALANCE'][assignedClusters.labels_==2],\n",
    "            color='green', marker='o', label='cluster 2')\n",
    "\n",
    "for (cx, cy) in assignedClusters_clust.cluster_centers_:\n",
    "    plt.plot(cx, cy, color='black', marker='x', mew=2)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('READ_AVERAGE')\n",
    "plt.ylabel('BALANCE')\n",
    "\n",
    "plt.title('3-means Clustering with centroids (50% sample)')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(assignedClusters.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
